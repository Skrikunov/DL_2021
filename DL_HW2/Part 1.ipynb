{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJWxXWJlFHfk"
   },
   "source": [
    "# Homework 2\n",
    "\n",
    "This assignment is to help you get used to PyTorch (and to improve your googling skills).\n",
    "\n",
    "If this is your first PyTorch experience, you may want to [start here](https://pytorch.org/tutorials/).\n",
    "\n",
    "While learning PyTorch, you will have lots of questions, like\n",
    "\n",
    "* how to choose between `.sqrt()` and `.sqrt_()`,\n",
    "* when to use `.view()` and how is it different from `.reshape()`,\n",
    "* which `dtype` to use etc.\n",
    "\n",
    "To find the answers, you are expected to google a lot and to refer to [documentation](https://pytorch.org/docs/stable/index.html). Quick documentation on functions and modules is available with `?` and `help()`, like so:\n",
    "\n",
    "```python\n",
    "help(torch.sqrt)\n",
    "```\n",
    "\n",
    "```python\n",
    "# to close the help bar, press `Esc` or `q`\n",
    "?torch.cat\n",
    "```\n",
    "\n",
    "In this assignment, <font color=\"red\">**you are NOT ALLOWED to:**</font>\n",
    "* use NumPy, SciPy or any other tensor library except PyTorch;\n",
    "* emulate PyTorch tensors (that are used for large arrays of numbers) with lists or tuples;\n",
    "* emulate any tensor functionality with other libraries/loops/indexing if it's directly native to PyTorch. Example:\n",
    "\n",
    "```python\n",
    "x = torch.rand(1_000_000)\n",
    "\n",
    "# Wrong: slow and unreadable\n",
    "for idx in range(x.numel()):\n",
    "    x[idx] = math.sqrt(x[idx])\n",
    "\n",
    "# Correct\n",
    "x.sqrt_()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWSHyGLvFHfl"
   },
   "source": [
    "## Part 1 (40 points total)\n",
    "\n",
    "**In this part only**, you are <font color=\"red\">**NOT ALLOWED**</font> to use any PyTorch submodules, including\n",
    "* `torch.nn`,\n",
    "* `torch.nn.functional` (in general, try to always avoid using it),\n",
    "* `torch.optim`,\n",
    "* `torch.utils.data`,\n",
    "* `torch.distributions`...\n",
    "\n",
    "Instead, use only PyTorch core functions, such as `torch.avg_pool1d(x)`, `torch.conv2d` or `torch.no_grad()`. Where possible, use special operators syntax (e.g. `x @ y`, `x += 17`, `x[None]`) or tensor methods (e.g. `x.to(y)`, `x.relu()`, `x.copy_(y)`).\n",
    "\n",
    "<br>\n",
    "\n",
    "**FAQ** (click to expand)\n",
    "\n",
    "<details>\n",
    "<summary><i>Hey look what's wrong with <code>torch.nn.functional</code>? I've always used it! It's in all the tutorials!</i></summary>\n",
    "<ul>\n",
    "<li>A huge portion of its functions are in PyTorch core. For example, there are <code>torch.max_pool1d_with_indices</code>, <code>torch.pdist</code>, <code>torch.batch_norm</code> etc.\n",
    "<li>Many parts of it, like <code>torch.nn.functional.tanh</code>, are explicitly deprecated.\n",
    "<li>In general, given the tendency of migrating <code>torch.nn.functional.*</code> into <code>torch.*</code>, I have a strong impression that they will soon deprecate the whole submodule (but that's just my hypothesis).\n",
    "<li><a href=\"https://discuss.pytorch.org/t/how-to-choose-between-torch-nn-functional-and-torch-nn-module/2800\">It's a</a> frequent <a href=\"https://www.reddit.com/r/pytorch/comments/afy3rt/torchnnfunctional/\">source</a> of <a href=\"https://discuss.pytorch.org/t/whats-the-difference-between-torch-nn-functional-and-torch-nn/681\">confusion</a>, especially for newbies.\n",
    "<li>It clutters the code. <code>x.softmax()</code> and <code>torch.softmax(x)</code> are better than <code>torch.nn.functional.softmax(x)</code> and <code>F.softmax(x)</code>.\n",
    "</ul>\n",
    "\n",
    "Though I have to admit you can't avoid it at all, e.g. there are unique <code>torch.nn.functional.triplet_margin_loss</code> and <code>torch.nn.functional.softmin</code>. But in this assignment, you can. ðŸ˜‰\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvVEGPdPFHf4"
   },
   "outputs": [],
   "source": [
    "# Determine the locations of auxiliary libraries and datasets.\n",
    "# `AUX_DATA_ROOT` is where 'notmnist.py', 'animation.py' and 'tiny-imagenet-2020.zip' are.\n",
    "\n",
    "# Detect if we are in Google Colaboratory\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "from pathlib import Path\n",
    "if IN_COLAB:\n",
    "    google.colab.drive.mount(\"/content/drive\")\n",
    "    \n",
    "    # Change this if you created the shortcut in a different location\n",
    "    AUX_DATA_ROOT = Path(\"/content/drive/My Drive/Deep Learning 2021 -- Home Assignment 2\")\n",
    "    \n",
    "    assert AUX_DATA_ROOT.is_dir(), \"Have you forgot to 'Add a shortcut to Drive'?\"\n",
    "    \n",
    "    import sys\n",
    "    sys.path.append(str(AUX_DATA_ROOT))\n",
    "else:\n",
    "    AUX_DATA_ROOT = Path(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gfwKfy9OdubD"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# 1. Libraries\n",
    "import torch\n",
    "import numpy as np               # results verification during grading\n",
    "\n",
    "import matplotlib.pyplot as plt  # 2D plot in task 1\n",
    "%matplotlib inline\n",
    "\n",
    "# 2. Extra custom code for this assignment\n",
    "from animation import Animation              # animations in task 2\n",
    "# if animations don't work, try uncommenting this line:\n",
    "from animation import AnimationMJPG as Animation\n",
    "from notmnist import load_notmnist           # dataset for task 3\n",
    "\n",
    "# 3. Your solution\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "%aimport part1_solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "043KDbWVFHgT"
   },
   "source": [
    "### Task 1 (3 points)\n",
    "\n",
    "$\\rho(\\theta)$ is defined in the polar coordinate system:\n",
    "\n",
    "$$\\rho(\\theta) = (1 + 0.9 \\cdot \\cos{8\\theta} ) \\cdot (1 + 0.1 \\cdot \\cos{24\\theta}) \\cdot (0.9 + 0.05 \\cdot \\cos {200\\theta}) \\cdot (1 + \\sin{\\theta})$$\n",
    "\n",
    "1. Create a **64-bit floating point** regular grid of 1000 values of $\\theta$ between $-\\pi$ and $\\pi$.\n",
    "2. Compute $\\rho(\\theta)$ at these points.\n",
    "3. Convert the result into Cartesian coordinates ([see here how](http://www.mathsisfun.com/polar-cartesian-coordinates.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWhKZT6zFHgV"
   },
   "outputs": [],
   "source": [
    "x, y = part1_solution.get_rho()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nyGT0_y8FHga"
   },
   "outputs": [],
   "source": [
    "# Run this cell and make sure the plot is correct\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.fill(x, y, color='green')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NRQuLaygFHgf"
   },
   "outputs": [],
   "source": [
    "assert \\\n",
    "    np.allclose(x.sum(), -1.9854999999997989, atol=1e-4) and \\\n",
    "    np.allclose(y.mean(), 0.44955, atol=1e-4), \\\n",
    "    \"Task 1: you've made an error somewhere\"\n",
    "print(\"Task 1: well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dwk1jMA7FHgj"
   },
   "source": [
    "### Task 2 (7 points)\n",
    "\n",
    "We will implement [Conway's Game of Life](https://en.wikipedia.org/wiki/Conway's_Game_of_Life) in PyTorch.\n",
    "\n",
    "![img](https://cdn.tutsplus.com/gamedev/authors/legacy/Stephane%20Beniak/2012/09/11/Preview_Image.png)\n",
    "\n",
    "In case you skipped the above hyperlink, here is the algorithm:\n",
    "* You have a 2D grid of cells, where each cell is \"alive\" or \"dead\" (has a value of `1` or `0` respectively).\n",
    "* At each step in time, the so-called \"generation update\" happens:\n",
    "  * any alive cell that has 2 or 3 alive neighbors survives, otherwise (0, 1 or 4+ neighbors) it dies;\n",
    "  * any dead cell with exactly 3 alive neighbors becomes alive.\n",
    "\n",
    "You are given a (slow) reference implementation of the generation update. Your task is to convert it to PyTorch (faster). Avoid datatype conversions, and, as always, remember to not use loops over tensor elements etc., just PyTorch operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JD3FAyY1FHgk"
   },
   "outputs": [],
   "source": [
    "def game_of_life_update_reference(alive_map):\n",
    "    \"\"\"\n",
    "    Game of Life update function (in-place).\n",
    "    \n",
    "    alive_map:\n",
    "        `numpy.ndarray`, ndim == 2, dtype == `numpy.int64`\n",
    "        The game map containing 0s (dead) an 1s (alive).\n",
    "    \"\"\"\n",
    "    # Count neighbours for each cell with convolution\n",
    "    num_alive_neighbors = np.zeros_like(alive_map)\n",
    "    h, w = alive_map.shape\n",
    "\n",
    "    for row in range(h):\n",
    "        for col in range(w):\n",
    "            for row_d in range(-1, 2):\n",
    "                for col_d in range(-1, 2):\n",
    "                    if row_d == col_d == 0:\n",
    "                        continue\n",
    "                    if 0 <= row + row_d < h and 0 <= col + col_d < w:\n",
    "                        num_alive_neighbors[row, col] += alive_map[row + row_d, col + col_d]\n",
    "    \n",
    "    # Apply game rules\n",
    "    new_alive_map = np.empty_like(alive_map)\n",
    "    for row in range(h):\n",
    "        for col in range(w):\n",
    "            born = num_alive_neighbors[row, col] == 3 and alive_map[row, col] == 0\n",
    "            survived = num_alive_neighbors[row, col] in (2,3) and alive_map[row, col] == 1\n",
    "            new_alive_map[row, col] = born or survived\n",
    "    \n",
    "    # Output the result\n",
    "    np.copyto(alive_map, new_alive_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wK8f1HMTFHgv"
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    # Generate a random initial map\n",
    "    alive_map_numpy = np.random.choice([0, 1], p=(0.5, 0.5), size=(100, 100)).astype(np.int64)\n",
    "    alive_map_torch = torch.from_numpy(alive_map_numpy).clone()\n",
    "\n",
    "    game_of_life_update_reference(alive_map_numpy)\n",
    "    part1_solution.game_of_life_update_torch(alive_map_torch)\n",
    "\n",
    "    # Results must be identical\n",
    "    assert np.allclose(alive_map_torch.numpy(), alive_map_numpy), \\\n",
    "        \"Your PyTorch implementation doesn't match `game_of_life_update_reference`.\"\n",
    "\n",
    "print(\"Task 2: well done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3Q6vQ7lFHgz"
   },
   "outputs": [],
   "source": [
    "animation = Animation(monochrome=True)\n",
    "\n",
    "# Initialize game field\n",
    "np.random.seed(666)\n",
    "alive_map = np.random.choice([0, 1], size=(100, 100)).astype(np.int64)\n",
    "alive_map = torch.from_numpy(alive_map)\n",
    "\n",
    "for _ in range(101):\n",
    "    animation.add_image((alive_map * 255).byte().numpy()[:, :, None])\n",
    "    part1_solution.game_of_life_update_torch(alive_map)\n",
    "\n",
    "animation.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2UeFAeYFHg4"
   },
   "outputs": [],
   "source": [
    "animation = Animation(monochrome=True)\n",
    "\n",
    "# A fun setup for your amusement\n",
    "alive_map = np.arange(100) % 2 + np.zeros((100, 100), dtype=np.int64)\n",
    "alive_map[48:52, 50] = 1\n",
    "\n",
    "alive_map = torch.from_numpy(alive_map)\n",
    "\n",
    "for _ in range(150):\n",
    "    animation.add_image((alive_map * 255).byte().numpy()[:, :, None])\n",
    "    part1_solution.game_of_life_update_torch(alive_map)\n",
    "\n",
    "animation.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uqe3Uys0FHg8"
   },
   "source": [
    "More fun with Game of Life: [video](https://www.youtube.com/watch?v=C2vgICfQawE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lhgyOraEFHg9"
   },
   "source": [
    "### Task 3 (30 points)\n",
    "\n",
    "This task is to teach you PyTorch's autograd (automatic differentiation) functionality. So, this time, don't code your own backprop manually like in the assignment â„–1.\n",
    "\n",
    "You have to solve yet another character recognition problem: *notMNIST* dataset of 10 letters and ~14 000 train samples.\n",
    "\n",
    "For this, we ask you to build a multilayer perceptron (*i.e. a neural network of linear layers*) from scratch using **low-level** PyTorch interface.\n",
    "\n",
    "Requirements:\n",
    "1. at least 82% validation accuracy,\n",
    "1. at least 2 linear layers,\n",
    "1. no convolutions,\n",
    "1. [categorical cross-entropy loss](https://gombru.github.io/2018/05/23/cross_entropy_loss/) (`x.log_softmax()` recommended for numerical stability),\n",
    "1. training and evaluation should in total **take at most 15 seconds** (roughly),\n",
    "1. no GPU.\n",
    "\n",
    "Tips:\n",
    "\n",
    "* This is a much simpler problem than that in homework 1. So don't use the structures from there (`Sequential`, `.forward()` etc.), they will be an overkill here. We suggest that your `NeuralNet.predict()` consists of 5-7 lines.\n",
    "* Pick random batches (either shuffle data before each epoch or sample each batch randomly).\n",
    "* Do not initialize weights with zeros ([learn why](https://stats.stackexchange.com/questions/27112/danger-of-setting-all-initial-weights-to-zero-in-backpropagation)). Gaussian noise with small variance will do.\n",
    "* 50 hidden neurons and a sigmoid nonlinearity will do for a start. Many ways to improve.\n",
    "* To improve accuracy, consider changing layers' sizes, nonlinearities, optimization parameters, weights initialization.\n",
    "\n",
    "Happy googling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IBQ8Zz9rFHg9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download and initialize dataset\n",
    "letters = 'ABCDEFGHIJ'\n",
    "X_train, y_train, X_val, y_val = map(torch.tensor, load_notmnist(letters=letters))\n",
    "X_train.squeeze_()\n",
    "X_val.squeeze_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UGgRCZtDFHhD"
   },
   "outputs": [],
   "source": [
    "# Display a part of the dataset\n",
    "fig, axarr = plt.subplots(2, 10, figsize=(10, 2))\n",
    "\n",
    "for idx, ax in enumerate(axarr.ravel()):\n",
    "    ax.imshow(X_train[idx], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(letters[y_train[idx]])\n",
    "\n",
    "fig.suptitle(\"Example ground truth labels\", y=1.08)\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yUp8x9MFHhH"
   },
   "outputs": [],
   "source": [
    "# Initialize the neural net\n",
    "np.random.seed(666)\n",
    "torch.manual_seed(666)\n",
    "\n",
    "model = part1_solution.NeuralNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a4LwAV5nfFtY"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "# Train\n",
    "part1_solution.train_on_notmnist(model, X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dE00xTMEjlSo"
   },
   "outputs": [],
   "source": [
    "# Run it on some validation samples\n",
    "example_batch = (torch.arange(20) + 1) * 31\n",
    "_, example_batch_predictions = model.predict(X_val[example_batch]).max(1)\n",
    "\n",
    "fig, axarr = plt.subplots(2, 10, figsize=(10, 2))\n",
    "\n",
    "for idx, ax in enumerate(axarr.ravel()):\n",
    "    ax.imshow(X_val[example_batch[idx]], cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(letters[example_batch_predictions[idx]])\n",
    "\n",
    "fig.suptitle(\"Example predictions\", y=1.08)\n",
    "fig.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rIIpwma6FHhb"
   },
   "outputs": [],
   "source": [
    "# Run it on all data, compute accuracies\n",
    "train_accuracy = part1_solution.accuracy(model, X_train, y_train) * 100\n",
    "val_accuracy = part1_solution.accuracy(model, X_val, y_val) * 100\n",
    "print(\"Training accuracy: %.2f, validation accuracy: %.2f\" % (train_accuracy, val_accuracy))\n",
    "\n",
    "assert val_accuracy >= 82.0, \"You have to do better\"\n",
    "print(\"Task 3: well done!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
